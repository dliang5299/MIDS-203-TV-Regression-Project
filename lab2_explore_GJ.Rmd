---
title: "lab2_explore_GJ"
author: "Godsee Joy"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages and original dataset 

```{r import, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message=FALSE)

# import data 
data <- read.csv("GSSv3.csv")

# import relevant libraries 
library(dplyr)
library(lmtest)
library(sandwich)
library(tidyverse)
library(patchwork)
library(GGally)
library(moments)
library(car)
library(ggplot2)

knitr::opts_chunk$set(message=FALSE)
theme_set(theme_minimal())
```




## Recoding Data and Missing Value Checks 

```{r data wrangling, include=FALSE}
# remove unused columns 
data <- data[, -which(names(data) %in% c("year", "id_", "ballot"))]
data <- subset(data, wrkstat != ".n:  No answer")
data <- subset(data, marital != ".n:  No answer")

# assessing -100 values in income 
summary(data$coninc)
sum(data$coninc == -100) # 196 observations have -100 

sum(data$coninc == 0) # 0 observations have $0 - I wonder if it is meant to be $0 as the codebook does not say? but they do have an option for no income data which they punch in as 0 but could be coded into the dataset as -100 

# look at of those with -100 income, what their work statuses are: 
data %>%
  filter(coninc == -100) %>%
  count(wrkstat) %>%
  mutate(proportion = round((n / sum(n)*100),2),
         count = n
         ) %>%
  select(wrkstat, proportion, count)

# decision: drop them - more consistent with GSS documentation of no income data 
data <- subset(data, coninc != -100)


data <- data %>%
  mutate(
    wrkstat = ifelse(wrkstat %in% c("Unemployed, laid off, looking for work","With a job, but not at work because of temporary illness, vacation, strike", "Keeping house", "Retired", "In school","Other"), "Not working", wrkstat),
    wrkstat = ifelse(wrkstat %in% c("Working full time","Working part time"), "Working", wrkstat),
    wrkstat = factor(wrkstat, levels = c("Working","Not working")),
    
    marital = ifelse(marital %in% c("Divorced", "Never married","Separated","Widowed"),"Not married",marital),
    marital = factor(marital, levels = c("Married","Not married")), 
    
    degree = factor(degree, levels = c("Less than high school","High school","Associate/junior college","Bachelor's","Graduate")),
    degree = relevel(degree, ref = "Graduate"),
    
    sex = factor(sex), 
    
    age = ifelse(age == ".n:  No answer", "", age),
    age = ifelse(age == "89 or older", "89", age),
    age = as.numeric(age),
    
    educ = ifelse(educ %in% c(".n:  No answer",".d:  Do not Know/Cannot Choose"), "", educ),
    educ = ifelse(educ == "No formal schooling", "0", educ),
    educ = as.numeric(educ),
    
    tvhours = ifelse(tvhours %in% c(".d:  Do not Know/Cannot Choose",".n:  No answer",".s:  Skipped on Web", ".i:  Inapplicable"), "", tvhours),
    tvhours = ifelse(tvhours == "0 hours", "0", tvhours),
    tvhours = ifelse(tvhours == "24 hours", "24", tvhours),
    tvhours = as.numeric(tvhours),
    
    hompop = as.numeric(hompop)
  ) 
```


```{r missing values}
# look at proportion missing values - confirm no missing data before splitting 

missing_proportion <- colMeans(is.na(data))
missing_proportion

# 33% missing tv hours

# analysis of how tv hours missing population different from pop without missing: 

# Create a data frame with rows having no missing values in tv hours or age 
df_complete <- data[complete.cases(data$tvhours), ]

# Create a data frame with rows having missing values in tv hours or age 
df_missing <- data[!complete.cases(data$tvhours), ]

df_complete <- df_complete[, -which(names(df_complete) %in% c("tvhours"))]
df_missing <- df_missing[, -which(names(df_missing) %in% c("tvhours"))]

# separating numeric from categorical 
numeric_cols <- sapply(df_complete, is.numeric)
categorical_cols <- !numeric_cols

# Plot histograms for numeric columns
par(mar = c(5, 4, 4, 2) + 0.1)
#par(mfrow=c(1, length(numeric_cols)))
for (col in names(df_complete)[numeric_cols]) {
  hist(df_complete[[col]], main=paste("Histogram of", col), xlab=col, border="black", col=rgb(0.7, 0.7, 0.7, alpha=0.5))
  hist(df_missing[[col]], col=rgb(1, 0.3, 0.3, alpha=0.5), add=TRUE, border="red")
  legend("topright", legend=c("Complete TV Hrs", "Missing TV Hrs"), fill=c(rgb(0.7, 0.7, 0.7, alpha=0.5), rgb(1, 0.3, 0.3, alpha=0.5)))
}

# Plot bar plots for categorical columns
#par(mfrow=c(1, length(categorical_cols)))
for (col in names(df_complete)[categorical_cols]) {
  counts_dfcomplete <- prop.table(table(df_complete[[col]]))
  counts_dfmissing <- prop.table(table(df_missing[[col]]))
  barplot(rbind(counts_dfcomplete, counts_dfmissing), beside=TRUE, legend=c("Complete TV Hrs", "Missing TV Hrs"), args.legend=list(x="topleft"), col=c("black", "blue"), main=col)

}
```

```{r}
# remove observations without age or tvhours (some missing in educ, but we use degree so it's okay) 
# started: 2,348, then dropped 3 that had no answer for marital or wrkstat and 196 with no income: 2,151
dim(data) # 2,151 rows 
data <- data[complete.cases(data[, c("age", "tvhours")]), ]
dim(data) # ending: 1,421 rows 
table(data$wrkstat)
```

## Splitting Final Cleaned Data into Train (30%) and Test (70%)

```{r split data, include=FALSE}
set.seed(23948729)
# to get 30% random sample to explore transformations and initial regressions 

# use same code across team to sample 
smp_size = floor(0.3 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
gss_train <- data[train_ind,]
gss_test <- data[-train_ind,]

```


## EDA Analysis 

```{r EDA, include=FALSE}
# EDA START 

# look at these for training data 
hist(gss_train$age)
table(gss_train$age_group)
table(gss_train$wrkstat)
table(gss_train$marital)
table(gss_train$degree)
hist(gss_train$educ)
hist(gss_train$tvhours)
hist(gss_train$hompop)
hist(gss_train$coninc)

```

```{r data wrangling3, include=FALSE}

   # grouping age by generations  
gss_train <- gss_train %>% mutate(    
    age_group = case_when(age <= 37 ~ 'GenZ/Millennial',
                          age >=38 & age <= 53 ~ 'GenX',
                          age >=54 & age <= 72 ~ 'BabyBoomers',
                          age >=73 ~ 'SilentGen'),
    age_group = factor(age_group, levels = c("GenZ/Millennial", "GenX", "BabyBoomers","SilentGen")),
    
    tvhours_log = log(tvhours + 1), 
    tvhours_sqrt = sqrt(tvhours), 
    
    coninc_log = log(coninc)
)

table(gss_train$age_group)

gss_test <- gss_test %>% mutate(    
    age_group = case_when(age <= 37 ~ 'GenZ/Millennial',
                          age >=38 & age <= 53 ~ 'GenX',
                          age >=54 & age <= 72 ~ 'BabyBoomers',
                          age >=73 ~ 'SilentGen'),
    age_group = factor(age_group, levels = c("GenZ/Millennial", "GenX", "BabyBoomers","SilentGen")),
    
    tvhours_log = log(tvhours + 1), 
    tvhours_sqrt = sqrt(tvhours), 
    
    coninc_log = log(coninc)
)

table(gss_test$age_group)
```


```{r plotsbars, include=FALSE}

## Including Plots

# seems roughly uniform, bit higher for older ages
plot(gss_train$age, gss_train$tvhours, 
     xlab = "Age", 
     ylab = "TV Hours Per Day",
     main = "Age and TV Hours")

plot(gss_train$age, gss_train$tvhours_log, 
     xlab = "Age", 
     ylab = "ln(TV Hours Per Day)",
     main = "Age and TV Hours")

plot(gss_train$age, gss_train$tvhours_sqrt, 
     xlab = "Age", 
     ylab = "sqrt(TV Hours Per Day)",
     main = "Age and TV Hours")

ggplot(gss_train, aes(x = age_group, y = tvhours)) + 
  geom_boxplot() +
  labs(title = "Generations and TV Hours", x = "Generation", y = "TV Hours per Day")

ggplot(gss_train, aes(x = age_group, y = tvhours_log)) + 
  geom_boxplot() +
  labs(title = "Generations and TV Hours", x = "Generation", y = "ln(TV Hours per Day)")

ggplot(gss_train, aes(x = age_group, y = tvhours_sqrt)) + 
  geom_boxplot() +
  labs(title = "Generations and TV Hours", x = "Generation", y = "sqrt(TV Hours per Day)")



# less tv time as hh size increases 
plot(gss_train$hompop, gss_train$tvhours, 
     xlab = "Household Size", 
     ylab = "TV Hours",
     main = "Scatter Plot of TV Hours and Household Size")

# income 
plot(gss_train$coninc, gss_train$tvhours, 
     xlab = "Household Income", 
     ylab = "TV Hours",
     main = "Scatter Plot of TV Hours and Household Income")

# degree 
ggplot(gss_train, aes(x = degree, y = tvhours)) + 
  geom_boxplot() +
  labs(title = "Education and TV Hours", x = "Highest Degree", y = "TV Hours per Day")

# work status 
ggplot(gss_train, aes(x = wrkstat, y = tvhours)) + 
  geom_boxplot() +
  labs(title = "Work Status and TV Hours", x = "Work Status", y = "TV Hours per Day")


# marital status 
ggplot(gss_train, aes(x = marital, y = tvhours)) + 
  geom_boxplot() +
  labs(title = "Marital Status and TV Hours", x = "Marital Status", y = "TV Hours per Day")


# sex 
ggplot(gss_train, aes(x = sex, y = tvhours)) + 
  geom_boxplot() +
  labs(title = "Sex and TV Hours", x = "Sex", y = "TV Hours per Day")

```



```{r}
# check for correlations across numeric data 

numeric_df <- gss_train[, sapply(gss_train, is.numeric)]  # Subset to include only numeric variables
correlation_matrix <- cor(numeric_df)
print(correlation_matrix)

# heatmap(correlation_matrix,
#         symm = TRUE,  # Display symmetrically
#         scale = "none",  # Do not scale the values
#         col = colorRampPalette(c("blue", "white", "red"))(20))
```


## Model Building 1 - Base Model Checks 
Conducting coeftest (t test) to see WITHIN models significant coefficients using robust SE. 

```{r basemodels, include=FALSE}
# base cases to compare 

print("-------Base 1: No Transf, Age Metric--------")
# .02 or 1.2 minutes more watching in TV for each additional year in age 
mod_base1 <- lm(tvhours ~ age, data = gss_test) # no transf, age metric 
summary(mod_base1)
coeftest(mod_base1, vcov = vcovHC(mod_base1))

```

```{r}
print("-------Base 2: TV hr log, Age Metric--------")

# 7% increase in tv hours for each additional year in age 
mod_base2 <- lm(tvhours_log ~ age, data = gss_test) # log tvhour, age metric 
summary(mod_base2)
coeftest(mod_base2, vcov = vcovHC(mod_base2))
```

```{r}
print("-------Base 3: TV hours, Age grouped--------")
mod_base3 <- lm(tvhours ~ age_group, data = gss_test) # log tvhour, age categ
summary(mod_base3)
coeftest(mod_base3, vcov = vcovHC(mod_base3))
```

```{r}
print("-------Base 4: TV hr log, Age grouped--------")

# baby boomers: 22% more tv watched than gen z/millennials 
mod_base4 <- lm(tvhours_log ~ age_group, data = gss_test) # log tvhour, age categ
summary(mod_base4)
coeftest(mod_base4, vcov = vcovHC(mod_base4))
```

```{r}
# add model residuals to best models 
gss_train <- gss_train %>%  
  mutate(base1_residuals = resid(mod_base1),# no transf 
         base2_residuals = resid(mod_base2), # log tv hours, age metric 
         base3_residuals = resid(mod_base3), # tv horus, age group 
         base4_residuals = resid(mod_base4)) # log tv horus, age group 

# assess age categories and tv hours scatter and then x's and residuals 
base1a <- gss_train %>%  
  ggplot(aes(x = age, y = tvhours)) + 
  geom_point() + geom_smooth(method = 'lm') + 
  labs(title ="TV Hrs, Age")

base1b <- gss_train %>%  
  ggplot(aes(x = age, y = base1_residuals)) + 
  geom_point() + stat_smooth(se = TRUE) +
  labs(title="TV Hrs, Age: Age x Residuals")

base1a | base1b

```

```{r}

base2a <- gss_train %>%  
  ggplot(aes(x = age, y = tvhours_log)) + 
  geom_point() + geom_smooth(method = 'lm') + 
  labs(title ="ln(TV Hrs), Age")

base2b <- gss_train %>%  
  ggplot(aes(x = age, y = base2_residuals)) + 
  geom_point() + stat_smooth(se = TRUE) +
  labs(title="ln(TV Hrs), Age: Age x Residuals")

base2a | base2b
```

```{r}

base3a <- gss_train %>%  
  ggplot(aes(x = age_group, y = tvhours)) + 
  geom_jitter(width = 0.2, alpha = 0.5) +  # Add jittered points to avoid overplotting
  stat_summary(fun = mean, geom = "point", size = 3, color = "red") + # Show mean
  labs(title = "TV Hrs by Generation")

base3b <- gss_train %>%  
  ggplot(aes(x = age_group, y = base3_residuals)) + 
  geom_boxplot() +  # Boxplot to show distribution of residuals
  labs(title = "Residuals by Generation")

# base3c <- gss_train %>% 
#   ggplot(aes(x = age_group, y = tvhours)) + 
#   geom_jitter(width = 0.2, alpha = 0.5, aes(color = age_group)) +  # Color-coded jitter
#   geom_line(data = mod_base3, aes(x = age_group, y = ), color = "red", linewidth = 1) +  # Overlay regression line
#   labs(title = "TV Hrs by Generation with Regression Line Base3")
# 
# base3c

base3a | base3b
```


## Model Building 2 - Complex Models to compare against base
Conducting F test to see BETWEEN models, added explanatory value - choosing 1% as alpha threshold 
Format: anova(long model, short model, test = "F")

Setting alpha level to 1% or .01 

```{r model building, include=FALSE}

print("-------Mod1: TV hr, Age grouped + sex--------")

# sex F not sig, going to exclude
mod1 <- lm(tvhours ~ age_group + sex, data = gss_test) 
summary(mod1)


coeftest(mod1, vcov = vcovHC(mod1))
anova(mod1, mod_base3, test = "F") 
```



```{r}
print("-------Mod2: TV hr, Age grouped + wrkstat--------")

# keep wrokstat (F test sig at 0%) - sig but decreases a bit of the older gen sig 
mod2 <- lm(tvhours ~ age_group + wrkstat, data = gss_test) 
summary(mod2)


coeftest(mod2, vcov = vcovHC(mod2))
anova(mod2, mod1, test = "F") #sig at 0%, keep wrkstat 
```

```{r}
print("-------Mod3: TV hr, Age grouped + workstatus + hhsize--------")

# F test not sig, exclude hompop
mod3 <- lm(tvhours ~ age_group + wrkstat + hompop, data = gss_test)  
summary(mod3)


coeftest(mod3, vcov = vcovHC(mod3))
anova(mod3, mod2, test = "F") # homepop not sig at all so exclude 
```


```{r}
print("-------Mod4: TV hr, Age grouped + workstatus + marital--------")

# sig F test at .1% 
mod4 <- lm(tvhours ~ age_group + wrkstat + marital, data = gss_test)  
summary(mod4)


coeftest(mod4, vcov = vcovHC(mod4))
anova(mod4, mod2, test = "F") # marital sig at .1% so keep 
```

```{r}
print("-------Mod5: TV hr, Age grouped + workstatus + marital + degree--------")

mod5 <- lm(tvhours ~ age_group + wrkstat + marital + degree, data = gss_test) # improved sig of age groups, and degrees also sig 
summary(mod5)


coeftest(mod5, vcov = vcovHC(mod5))
anova(mod5, mod4, test = "F") # degree sig at .1% level so keep
```

```{r}
print("-------Mod6: TV hr, Age grouped + workstatus + marital + degree + inc--------")

mod6 <- lm(tvhours ~ age_group + wrkstat + marital + degree + coninc, data = gss_test) # income reduced effect of education, coef sig at 5% (though t test coeftest shows 1%); improved sig or the genx group - maybe exclude? 
summary(mod6)


coeftest(mod6, vcov = vcovHC(mod6))
anova(mod6, mod5, test = "F") # income sig at 5% level so exclude?
```

```{r}
print("-------Mod7: TV hr, Age grouped + workstatus + marital + degree + log(inc)--------")

mod7 <- lm(tvhours ~ age_group + wrkstat + marital + degree + coninc_log, data = gss_test) # not sig - don't log income
summary(mod7)

coeftest(mod7, vcov = vcovHC(mod7))
anova(mod7, mod5, test = "F")
```

```{r}
# testing interactions of age with wrkstat, marital, degree: 
mod8 <- lm(tvhours ~ age_group + wrkstat + age_group*wrkstat + marital + degree + coninc, data = gss_test) # not sig 
summary(mod8)


coeftest(mod8, vcov = vcovHC(mod8))
```

```{r}
mod9 <- lm(tvhours ~ age_group + wrkstat + age_group*marital + marital + degree + coninc, data = gss_test) # interactions slightly sig but takes sig from generation categories 
summary(mod9)

coeftest(mod9, vcov = vcovHC(mod9))
```

```{r}
mod10 <- lm(tvhours ~ age_group + wrkstat + marital + degree + degree*age_group + coninc, data = gss_test) # interactions not sig 
summary(mod10)

coeftest(mod10, vcov = vcovHC(mod10))
```

```{r}

# one more model with final result and log tvhours to see impact 

```

## More Model evaluation 
Goodness of fit
- R is correlation 
- R squared = explained variance / total variance 
- sum of squares are unscaled versions of the variances 
- predictions can never get worse 
- R squared *not* measure of practical significance 
    - lots of fields where low R-squared is common (especially human behavior modeling)
- if you have a lot of vars, there are others that penalize for adding to many: 
    - adjusted R^2, AIC (Akaike information criteria), BIC (bayesian information criteria)

```{r}


```

## Assess practical significant - Cohen's d, others from Mark's doc?
- these are more for t tests , think we focus on comparing between generations - refer to literature 

## Still explore the CLM assumptions? maybe the first 3: IID we have, no perfect collinearity is also fine
- linear conditional mean
- homosked (okay, we use robust SE)
- normally distributed errors 

```{r}
# formatting regressions into stargazer table 

# add AIC (Akaike information criteria), BIC (bayesian information criteria) in addition to R squared?
# stargazer(mod,
#           type="text",
#           header = F,
#           title ="Predicting House Race Number of Votes Using Party and Campaign Disbursements",
#           covariate.labels = 
#             c("Total Disbursements",
#               "Candidate Party: Other",
#               "Candidate Party: Republican"),
#           dep.var.labels = "Total Number of Votes",
#           se= list(robust_se),
#           digits = 2,
#           notes.align = "l",
#           notes = "lm function with Robust SE",
#           notes.append = TRUE
#           )

library(stargazer)
base1robust_se <- sqrt(diag(vcovHC(mod_base1)))
base3robust_se <- sqrt(diag(vcovHC(mod_base3)))
robust_se2 <- sqrt(diag(vcovHC(mod2)))
robust_se4 <- sqrt(diag(vcovHC(mod4)))
robust_se5 <- sqrt(diag(vcovHC(mod5)))
robust_se6 <- sqrt(diag(vcovHC(mod6)))

# adding AIC and BIC
modbase1_aic <- AIC(mod_base1)
modbase2_bic <- BIC(mod_base3)

# Generate a stargazer table including AIC and BIC
stargazer(model, type = "text", 
          add.lines = list(c("AIC", format(model_aic, digits = 4)), 
                           c("BIC", format(model_bic, digits = 4))))

# Generate the regression table, omitting coefficients for specific dummy variables
stargazer(mod_base1, mod_base3, mod2, mod4, mod5, mod6, type = "text", 
          title = "Regression Results",
          align = TRUE, 
          dep.var.labels.include = TRUE,
          dep.var.labels = "Hours of TV Watched per Day",
          covariate.labels = c("Age (raw)", "Generation X", "Baby Boomers", "Silent Generation", "Not Working", "Not Married","Degree: Less than High School","Degree: High School","Degree: Associate/Junior High","Degree: Bachelor's", "Family Income (adjusted for inflation"),  # Labels for independent variables
          #omit = c("wrkstatOther","degreeHigh school","degreeAssociate/junior college"),  # Omit coefficients for specific dummy variables
          se = list(base1robust_se, base3robust_se, robust_se2, robust_se4, robust_se5, robust_se6)
          )
```

